{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b240643",
   "metadata": {},
   "source": [
    "\n",
    "# Train / Validation / Test Splits with Time-Series Features\n",
    "\n",
    "We partition the historical portion of `data/processed/merged_data_model_ready_interactions.csv` (2024-03-14 → 2025-08-17) into train/validation/test folds. Rows from 2025-08-18 → 2025-09-14 remain untouched as the final forecast horizon.\n",
    "\n",
    "**Default cutoffs (adjust as needed):**\n",
    "- Train: 2024-03-14 → 2025-05-31\n",
    "- Validation: 2025-06-01 → 2025-06-30\n",
    "- Test: 2025-07-01 → 2025-08-17\n",
    "- Holdout: 2025-08-18 → 2025-09-14 (not used for fitting/eval; reserved for final scoring)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237a89c",
   "metadata": {},
   "source": [
    "## Imports & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aca0cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T17:35:05.524211Z",
     "iopub.status.busy": "2025-11-07T17:35:05.523945Z",
     "iopub.status.idle": "2025-11-07T17:35:05.873796Z",
     "shell.execute_reply": "2025-11-07T17:35:05.873591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train end: 2025-05-31\n",
      "Validation end: 2025-06-30\n",
      "Test end: 2025-08-17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_PATH = BASE_DIR / 'data' / 'processed' / 'merged_data_model_ready_interactions.csv'\n",
    "OUTPUT_DIR = BASE_DIR / 'data' / 'processed' / 'timeseries_splits'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_END = pd.Timestamp('2025-05-31')\n",
    "VAL_END = pd.Timestamp('2025-06-30')\n",
    "TEST_END = pd.Timestamp('2025-08-17')\n",
    "\n",
    "print('Train end:', TRAIN_END.date())\n",
    "print('Validation end:', VAL_END.date())\n",
    "print('Test end:', TEST_END.date())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f351f1f",
   "metadata": {},
   "source": [
    "## Load Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8720efeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T17:35:05.875120Z",
     "iopub.status.busy": "2025-11-07T17:35:05.875028Z",
     "iopub.status.idle": "2025-11-07T17:35:06.958796Z",
     "shell.execute_reply": "2025-11-07T17:35:06.958598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (275000, 62)\n",
      "Date range: 2024-03-14 → 2025-09-14\n",
      "Departments: [6, 90, 9, 41, 67]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>dt</th>\n",
       "      <th>cases</th>\n",
       "      <th>trucks</th>\n",
       "      <th>state_name</th>\n",
       "      <th>market_area_nbr</th>\n",
       "      <th>region_nbr</th>\n",
       "      <th>dept_desc</th>\n",
       "      <th>gmm_name</th>\n",
       "      <th>...</th>\n",
       "      <th>trend_party_interaction</th>\n",
       "      <th>trend_dairy_interaction</th>\n",
       "      <th>trend_cameras_interaction</th>\n",
       "      <th>bts_sporting_flag</th>\n",
       "      <th>bts_celebration_flag</th>\n",
       "      <th>sports_event_sporting_flag</th>\n",
       "      <th>hot_back_to_school_flag</th>\n",
       "      <th>sales_tax_back_to_school_flag</th>\n",
       "      <th>sales_tax_bts_sporting</th>\n",
       "      <th>cpi_food_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>10002</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>296</td>\n",
       "      <td>26</td>\n",
       "      <td>CAMERAS AND SUPPLIES</td>\n",
       "      <td>GENERAL MERCHANDISE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>10002</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>296</td>\n",
       "      <td>26</td>\n",
       "      <td>CAMERAS AND SUPPLIES</td>\n",
       "      <td>GENERAL MERCHANDISE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10002</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>296</td>\n",
       "      <td>26</td>\n",
       "      <td>CAMERAS AND SUPPLIES</td>\n",
       "      <td>GENERAL MERCHANDISE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>10001</td>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MD</td>\n",
       "      <td>285</td>\n",
       "      <td>22</td>\n",
       "      <td>DAIRY</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10004</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>LA</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>SPORTING GOODS</td>\n",
       "      <td>GENERAL MERCHANDISE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dept_id  store_id         dt  cases  trucks state_name  market_area_nbr  \\\n",
       "0        6     10002 2025-02-20   63.0     2.0         NC              296   \n",
       "1        6     10002 2025-02-28   56.0     2.0         NC              296   \n",
       "2        6     10002 2025-02-19   62.0     2.0         NC              296   \n",
       "3       90     10001 2025-02-25   67.0     3.0         MD              285   \n",
       "4        9     10004 2025-02-07   53.0     2.0         LA               66   \n",
       "\n",
       "   region_nbr             dept_desc             gmm_name  ...  \\\n",
       "0          26  CAMERAS AND SUPPLIES  GENERAL MERCHANDISE  ...   \n",
       "1          26  CAMERAS AND SUPPLIES  GENERAL MERCHANDISE  ...   \n",
       "2          26  CAMERAS AND SUPPLIES  GENERAL MERCHANDISE  ...   \n",
       "3          22                 DAIRY                 FOOD  ...   \n",
       "4          13        SPORTING GOODS  GENERAL MERCHANDISE  ...   \n",
       "\n",
       "  trend_party_interaction  trend_dairy_interaction  trend_cameras_interaction  \\\n",
       "0                     0.0                     0.00                       0.64   \n",
       "1                     0.0                     0.00                       0.44   \n",
       "2                     0.0                     0.00                       0.64   \n",
       "3                     0.0                     0.02                       0.00   \n",
       "4                     0.0                     0.00                       0.00   \n",
       "\n",
       "   bts_sporting_flag  bts_celebration_flag  sports_event_sporting_flag  \\\n",
       "0                  0                     0                           0   \n",
       "1                  0                     0                           0   \n",
       "2                  0                     0                           0   \n",
       "3                  0                     0                           0   \n",
       "4                  0                     0                           0   \n",
       "\n",
       "   hot_back_to_school_flag  sales_tax_back_to_school_flag  \\\n",
       "0                        0                              0   \n",
       "1                        0                              0   \n",
       "2                        0                              0   \n",
       "3                        0                              0   \n",
       "4                        0                              0   \n",
       "\n",
       "   sales_tax_bts_sporting  cpi_food_gap  \n",
       "0                       0        13.675  \n",
       "1                       0        13.675  \n",
       "2                       0        13.675  \n",
       "3                       0        13.675  \n",
       "4                       0        13.675  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['dt'], low_memory=False)\n",
    "print('Shape:', df.shape)\n",
    "print('Date range:', df['dt'].min().date(), '→', df['dt'].max().date())\n",
    "print('Departments:', df['dept_id'].unique().tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c8f86",
   "metadata": {},
   "source": [
    "## Split by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6573045e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T17:35:06.959906Z",
     "iopub.status.busy": "2025-11-07T17:35:06.959840Z",
     "iopub.status.idle": "2025-11-07T17:35:07.037462Z",
     "shell.execute_reply": "2025-11-07T17:35:07.037253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 222000\n",
      "Validation rows: 15000\n",
      "Test rows: 24000\n",
      "Holdout rows: 14000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_mask = df['dt'] <= TEST_END\n",
    "holdout_mask = df['dt'] > TEST_END\n",
    "\n",
    "history_df = df.loc[history_mask].copy()\n",
    "holdout_df = df.loc[holdout_mask].copy()\n",
    "\n",
    "train_mask = history_df['dt'] <= TRAIN_END\n",
    "val_mask = (history_df['dt'] > TRAIN_END) & (history_df['dt'] <= VAL_END)\n",
    "test_mask = (history_df['dt'] > VAL_END)\n",
    "\n",
    "train_df = history_df.loc[train_mask].copy()\n",
    "val_df = history_df.loc[val_mask].copy()\n",
    "test_df = history_df.loc[test_mask].copy()\n",
    "\n",
    "print('Train rows:', len(train_df))\n",
    "print('Validation rows:', len(val_df))\n",
    "print('Test rows:', len(test_df))\n",
    "print('Holdout rows:', len(holdout_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8911252",
   "metadata": {},
   "source": [
    "\n",
    "## Helper: Build Lag/Rolling Features Safely\n",
    "\n",
    "We define a function that, given a DataFrame (train/val/test), computes lagged and rolling statistics per `(store_id, dept_id)` using only past data. For validation/test, we prepend the previous splits' history so the rolling window has context, then drop the extra rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b77b2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T17:35:07.038840Z",
     "iopub.status.busy": "2025-11-07T17:35:07.038762Z",
     "iopub.status.idle": "2025-11-07T17:35:07.041710Z",
     "shell.execute_reply": "2025-11-07T17:35:07.041544Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_lag_features(target_df, history_df=None, group_cols=('store_id','dept_id'), date_col='dt'):\n",
    "    \"\"\"Return target_df with lag/rolling features. history_df provides prior rows (train or train+val).\"\"\"\n",
    "    if history_df is not None:\n",
    "        concat_df = pd.concat([history_df, target_df], axis=0)\n",
    "    else:\n",
    "        concat_df = target_df.copy()\n",
    "\n",
    "    group_list = list(group_cols)\n",
    "    concat_df = concat_df.sort_values(group_list + [date_col])\n",
    "\n",
    "    for lag in [1, 7, 14]:\n",
    "        concat_df[f'cases_lag_{lag}'] = concat_df.groupby(group_list)['cases'].shift(lag)\n",
    "    concat_df['cases_ma_7'] = concat_df.groupby(group_list)['cases'].rolling(window=7, min_periods=1).mean().reset_index(level=group_list, drop=True)\n",
    "    concat_df['cases_ma_14'] = concat_df.groupby(group_list)['cases'].rolling(window=14, min_periods=1).mean().reset_index(level=group_list, drop=True)\n",
    "    concat_df['cases_std_7'] = concat_df.groupby(group_list)['cases'].rolling(window=7, min_periods=1).std().reset_index(level=group_list, drop=True)\n",
    "\n",
    "    concat_df['trucks_lag_1'] = concat_df.groupby(group_list)['trucks'].shift(1)\n",
    "    concat_df['trucks_lag_7'] = concat_df.groupby(group_list)['trucks'].shift(7)\n",
    "    concat_df['trucks_ma_7'] = concat_df.groupby(group_list)['trucks'].rolling(window=7, min_periods=1).mean().reset_index(level=group_list, drop=True)\n",
    "\n",
    "    result = concat_df.loc[concat_df.index.isin(target_df.index)].copy()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be08277",
   "metadata": {},
   "source": [
    "\n",
    "def add_lag_features(target_df, history_df=None, group_cols=('store_id','dept_id'), date_col='dt'):\n",
    "    \"\"\"Return target_df with lag/rolling features. history_df provides prior rows (train or train+val).\"\"\"\n",
    "    if history_df is not None:\n",
    "        concat_df = pd.concat([history_df, target_df], axis=0)\n",
    "    else:\n",
    "        concat_df = target_df.copy()\n",
    "\n",
    "    concat_df = concat_df.sort_values(list(group_cols) + [date_col])\n",
    "    for lag in [1, 7, 14]:\n",
    "        concat_df[f'cases_lag_{lag}'] = concat_df.groupby(group_cols)['cases'].shift(lag)\n",
    "    concat_df['cases_ma_7'] = concat_df.groupby(group_cols)['cases'].rolling(window=7, min_periods=1).mean().reset_index(level=group_cols, drop=True)\n",
    "    concat_df['cases_ma_14'] = concat_df.groupby(group_cols)['cases'].rolling(window=14, min_periods=1).mean().reset_index(level=group_cols, drop=True)\n",
    "    concat_df['cases_std_7'] = concat_df.groupby(group_cols)['cases'].rolling(window=7, min_periods=1).std().reset_index(level=group_cols, drop=True)\n",
    "\n",
    "    concat_df['trucks_lag_1'] = concat_df.groupby(group_cols)['trucks'].shift(1)\n",
    "    concat_df['trucks_lag_7'] = concat_df.groupby(group_cols)['trucks'].shift(7)\n",
    "    concat_df['trucks_ma_7'] = concat_df.groupby(group_cols)['trucks'].rolling(window=7, min_periods=1).mean().reset_index(level=group_cols, drop=True)\n",
    "\n",
    "    result = concat_df.loc[concat_df.index.isin(target_df.index)].copy()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d098244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T17:35:07.042731Z",
     "iopub.status.busy": "2025-11-07T17:35:07.042676Z",
     "iopub.status.idle": "2025-11-07T17:35:07.900459Z",
     "shell.execute_reply": "2025-11-07T17:35:07.900249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train lags nulls: {'cases_lag_1': 500, 'cases_lag_7': 3500, 'cases_lag_14': 7000}\n",
      "Val lags nulls: {'cases_lag_1': 0, 'cases_lag_7': 0, 'cases_lag_14': 0}\n",
      "Test lags nulls: {'cases_lag_1': 0, 'cases_lag_7': 0, 'cases_lag_14': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_with_lags = add_lag_features(train_df)\n",
    "val_with_lags = add_lag_features(val_df, history_df=train_df)\n",
    "test_with_lags = add_lag_features(test_df, history_df=pd.concat([train_df, val_df]))\n",
    "\n",
    "print('Train lags nulls:', train_with_lags[['cases_lag_1','cases_lag_7','cases_lag_14']].isnull().sum().to_dict())\n",
    "print('Val lags nulls:', val_with_lags[['cases_lag_1','cases_lag_7','cases_lag_14']].isnull().sum().to_dict())\n",
    "print('Test lags nulls:', test_with_lags[['cases_lag_1','cases_lag_7','cases_lag_14']].isnull().sum().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d0c3d",
   "metadata": {},
   "source": [
    "## Save Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ea04a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T17:35:07.901640Z",
     "iopub.status.busy": "2025-11-07T17:35:07.901558Z",
     "iopub.status.idle": "2025-11-07T17:35:12.265512Z",
     "shell.execute_reply": "2025-11-07T17:35:12.265233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train/val/test/holdout files to /Users/chanamalluvinay/Documents/wmt_proj/data/processed/timeseries_splits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_with_lags = add_lag_features(train_df)\n",
    "val_with_lags = add_lag_features(val_df, history_df=train_df)\n",
    "test_with_lags = add_lag_features(test_df, history_df=pd.concat([train_df, val_df]))\n",
    "\n",
    "train_with_lags.to_csv(OUTPUT_DIR / 'train_timeseries.csv', index=False)\n",
    "val_with_lags.to_csv(OUTPUT_DIR / 'val_timeseries.csv', index=False)\n",
    "test_with_lags.to_csv(OUTPUT_DIR / 'test_timeseries.csv', index=False)\n",
    "holdout_df.to_csv(OUTPUT_DIR / 'holdout_forecast_window.csv', index=False)\n",
    "\n",
    "print('Saved train/val/test/holdout files to', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa7bfe",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "- Adjust `TRAIN_END` and `VAL_END` at the top if you need different cutoffs.\n",
    "- The lag features currently cover cases/trucks; extend the helper function for additional metrics as needed.\n",
    "- Forecast rows (with `cases` null) live beyond the test split and can be scored after a model is trained.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
